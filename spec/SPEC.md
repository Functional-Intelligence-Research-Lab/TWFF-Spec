# TWFF Specification

**Version:** 0.1.0
**Status:** Draft
**Published:** 2026-02-16
**Authors:** Functional Intelligence Research Lab (FIRL)
**License:** Apache-2.0 (see [LICENSE](./LICENSE))

---

## Abstract

The Tracked Writing File Format (TWFF) is an open container format for packaging a written document alongside a deterministic audit trail of its composition process. TWFF enables *Verifiable Effort*: a cryptographic record that an author can voluntarily disclose to verify the authenticity of their work without relying on probabilistic AI detection systems.

---

## Status of This Document

This document is a **Draft Specification**.

The schema and event types defined here constitute the normative v0.1 release. Breaking changes will be issued under a new version number. Non-breaking additions (new optional fields, new event types) may be added with a minor version increment.

Feedback and proposals: open an issue at [github.com/Functional-Intelligence-Research-Lab/twff](https://github.com/Functional-Intelligence-Research-Lab/twff)

---

## 1. Motivation

### 1.1 The Detection Failure

AI content detectors operate on a fundamental statistical premise: given a body of text, estimate the probability that it was generated by a language model rather than a human author. This architecture has three structural problems.

**It is biased.** Research presented at NeurIPS 2023 demonstrates that detection models systematically misclassify writing by non-native English speakers as AI-generated at significantly higher rates than native speakers. Stanford analysis confirmed false positive rates of 61% on TOEFL essay samples. Linguistic diversity is treated as statistical anomaly.

**It is not auditable.** Every major commercial detector operates on proprietary algorithms. No student has ever received a meaningful technical explanation of a false positive. The vendor produces a score; the institution acts on it; the student bears the consequence. There is no appeal path grounded in evidence.

**It is not solvable.** Detection accuracy is bounded by the distributional shift between training data and deployment data. As language models evolve and prompting techniques advance, the gap between what detectors claim and what they deliver widens toward infinity. This is a mathematical constraint, not an engineering problem.

### 1.2 The Proposed Shift

TWFF reframes the question.

- **Wrong question:** *Can we estimate the probability that this text was machine-generated?*
- **Right question:** *Can we preserve and verify the record of how this text was produced?*

The first approach produces confidence intervals, false positives, and adversarial relationships. The second produces a deterministic, cryptographically-verifiable record of human effort.

### 1.3 Legal Context

The EU AI Act (Regulation 2024/1689), in force from August 2024, establishes binding transparency requirements for AI systems used in high-risk contexts including education. Article 50 requires machine-readable labelling of AI-generated content. Articles 52 and Recital 72 require that such systems be explainable and subject to human oversight.

AI detectors satisfy none of these requirements. TWFF is designed to satisfy all of them.

---

## 2. Terminology

The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this document are to be interpreted as described in [RFC 2119](https://www.rfc-editor.org/rfc/rfc2119).

| Term | Definition |
|---|---|
| **Container** | A `.twff` file; a ZIP archive conforming to this specification |
| **Process Log** | The `meta/process-log.json` file recording composition events |
| **Session** | A bounded writing period, delimited by `session_start` and `session_end` events |
| **Verifiable Effort** | A disclosure that allows a third party to independently verify the composition process |
| **Author** | The human writer whose process is being recorded |
| **Implementer** | Any software system producing or consuming TWFF containers |

---

## 3. Container Format

### 3.1 File Extension and MIME Type

- File extension: `.twff`
- MIME type: `application/vnd.twff+zip` (pending IANA registration)

### 3.2 ZIP Structure

A TWFF container is a valid ZIP archive (ZIP64 MAY be used for large containers). The archive MUST contain the following structure:

```
document.twff  (ZIP archive)
├── content/
│   ├── document.xhtml           REQUIRED — primary written work
│   ├── images/                  OPTIONAL — embedded images
│   └── assets/                  OPTIONAL — supporting files (bibliography, etc.)
├── meta/
│   ├── process-log.json         REQUIRED — composition event log
│   ├── manifest.xml             RECOMMENDED — container manifest
│   └── chat-transcript.json     OPTIONAL — full AI conversation history
└── META-INF/
    └── signatures.xml           OPTIONAL — cryptographic signatures
```

### 3.3 Content Format

The primary content file (`content/document.xhtml`) MUST be valid XHTML 1.1 or XHTML5. XHTML is required because:

- It is XML-based and strictly parseable, enabling reliable position mapping
- It supports `<span data-*>` attributes for annotation embedding
- It is transformable to PDF, DOCX, and HTML without loss
- It is human-readable

Implementers MAY include additional content files (plain text, LaTeX source) under `content/` as supplementary materials.

### 3.4 Manifest

If present, `meta/manifest.xml` MUST list all files in the container with their media types, following the EPUB package.opf convention:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<manifest>
  <item id="content" href="content/document.xhtml" media-type="application/xhtml+xml"/>
  <item id="log"     href="meta/process-log.json"  media-type="application/json"/>
  <item id="chat"    href="meta/chat-transcript.json" media-type="application/json"/>
</manifest>
```

---

## 4. Process Log Schema

### 4.1 Top-Level Fields

The `meta/process-log.json` file MUST be valid JSON conforming to the following schema. See `spec/process-log.schema.json` for the machine-readable JSON Schema.

| Field | Type | Required | Description |
|---|---|---|---|
| `version` | string | REQUIRED | Spec version, e.g. `"0.1.0"` |
| `session_id` | string (UUID) | REQUIRED | UUID v4 identifying this session |
| `user_id` | string | REQUIRED | Anonymous, user-generated identifier. MUST NOT contain PII. |
| `start_time` | string (ISO 8601) | REQUIRED | Session start timestamp in UTC, e.g. `"2026-02-16T09:00:00Z"` |
| `end_time` | string (ISO 8601) | REQUIRED | Session end timestamp in UTC |
| `content_source` | string | REQUIRED | Path to primary content file within container, e.g. `"content/document.xhtml"` |
| `events` | array | REQUIRED | Ordered array of event objects (see §4.2) |
| `_integrity` | object | RECOMMENDED | Integrity hash block (see §5) |

### 4.2 Event Object

Each element of `events` MUST conform to:

| Field | Type | Required | Description |
|---|---|---|---|
| `timestamp` | string (ISO 8601 UTC) | REQUIRED | When the event occurred |
| `type` | string | REQUIRED | Event type identifier (see §4.3) |
| `meta` | object | REQUIRED | Type-specific metadata. MUST be `{}` if no metadata applies. |

Events MUST be ordered chronologically by `timestamp`.

### 4.3 Event Types

#### `session_start`
Marks the beginning of a writing session. MUST be the first event in `events`.
`meta`: `{}`

#### `session_end`
Marks the end of a writing session. MUST be the last event in `events`.
`meta`: `{}`

#### `edit`
Records a human typing or deletion action.

| `meta` field | Type | Required | Description |
|---|---|---|---|
| `position_start` | integer | REQUIRED | Character offset of edit start in content file |
| `position_end` | integer | REQUIRED | Character offset of edit end |
| `source` | string | REQUIRED | Always `"human"` for this event type |

Note: TWFF does NOT record keystroke content, only character counts and positions.

#### `paste`
Records text pasted from an external source.

| `meta` field | Type | Required | Description |
|---|---|---|---|
| `char_count` | integer | REQUIRED | Number of characters pasted |
| `source` | string | REQUIRED | `"external"` for clipboard paste; `"ai"` if from an AI tool |
| `position_start` | integer | REQUIRED | Character offset where paste was inserted |
| `position_end` | integer | REQUIRED | Character offset of end of pasted content |
| `output_preview` | string | OPTIONAL | First 100 characters of pasted content |

#### `ai_interaction`
Records an AI assistant invocation.

| `meta` field | Type | Required | Description |
|---|---|---|---|
| `interaction_type` | string | REQUIRED | See interaction type values below |
| `model` | string | REQUIRED | Model identifier, e.g. `"gpt-4o"`, `"claude-sonnet-4-6"` |
| `input_preview` | string | OPTIONAL | First 100 characters of the prompt |
| `output_preview` | string | OPTIONAL | First 50 characters of the AI output |
| `output_length` | integer | RECOMMENDED | Character count of AI output |
| `position_start` | integer | RECOMMENDED | Character offset where output was inserted |
| `position_end` | integer | RECOMMENDED | Character offset of end of inserted output |
| `acceptance` | string | RECOMMENDED | See acceptance values below |

**`interaction_type` values:**

| Value | Description |
|---|---|
| `brainstorm` | AI generated ideas or outline |
| `draft` | AI wrote a full passage |
| `paraphrase` | AI rewrote existing text |
| `summarize` | AI summarized content |
| `expand` | AI expanded a short phrase |
| `continue` | AI continued from cursor |
| `completion` | Inline tab-completion |

**`acceptance` values:**

| Value | Description |
|---|---|
| `fully_accepted` | All output used as-is |
| `partially_accepted` | Some output used, some discarded |
| `modified` | Output used but significantly rewritten |
| `rejected` | Output discarded entirely |

#### `chat_interaction`
Records a multi-turn AI conversation (e.g. asking for feedback on a draft).

| `meta` field | Type | Required | Description |
|---|---|---|---|
| `message_count` | integer | REQUIRED | Number of messages in the exchange |
| `message_preview` | string | OPTIONAL | First 100 characters of the opening message |
| `source_file` | string | OPTIONAL | Path to `chat-transcript.json` within the container |

#### `focus_change`
Records the author navigating away from the editor window.

| `meta` field | Type | Required | Description |
|---|---|---|---|
| `duration_ms` | integer | REQUIRED | Duration of focus loss in milliseconds |

#### `checkpoint`
Records a periodic auto-save snapshot. Implementers SHOULD emit checkpoints at regular intervals (recommended: every 30–60 seconds of active editing).

| `meta` field | Type | Required | Description |
|---|---|---|---|
| `char_count_total` | integer | REQUIRED | Total character count at checkpoint |
| `word_count_total` | integer | RECOMMENDED | Total word count at checkpoint |
| `position` | integer | OPTIONAL | Approximate cursor position |

---

## 5. Data Integrity

### 5.1 Overview

TWFF process logs use a **per-event chained hash** model. Each event in the
`events` array carries a `_hash` field whose value is a SHA-256 hash of the
current event's data chained with the hash of the preceding event. This
structure means:

1. Any modification to an event invalidates that event's hash **and all
   subsequent event hashes**.
2. Any insertion or deletion of events is detectable — the chain breaks.
3. Verification requires only the `session_id` and the `events` array — no
   external keys or authorities.

### 5.2 Per-Event Hash (`_hash`)

Each event SHOULD include a `_hash` field computed as follows:

```
event_payload := {
    "timestamp":      event.timestamp,
    "type":           event.type,
    "meta":           event.meta      // compact JSON, keys sorted
}

hash_input := JSON.compact_sorted(event_payload)
           + "|"
           + previous_hash           // empty string "" for first event
           + "|"
           + session_id

event._hash := hex( SHA-256( UTF-8( hash_input ) ) )
```

Where:
- `JSON.compact_sorted(x)` means JSON serialized with no extra whitespace and
  all object keys sorted lexicographically (`sort_keys=True` in Python, or
  `JSON.stringify(x, Object.keys(x).sort())` equivalent in JavaScript).
- `previous_hash` is the `_hash` value of the immediately preceding event.
  For the first event (`session_start`), `previous_hash` is the empty string `""`.
- `session_id` is the UUID v4 from the top-level `session_id` field.
- `|` is a literal ASCII pipe character used as a separator.

**Schema addition:** The event schema defined in §4.2 is extended:

| Field   | Type   | Required    | Description |
|---------|--------|-------------|-------------|
| `_hash` | string | RECOMMENDED | Hex SHA-256 per-event chain hash (see §5.2) |

The `_hash` field MUST NOT be included in the `event_payload` during hash
computation (it is the output, not an input).

### 5.3 Top-Level `_integrity` Block

Conformant producers SHOULD include a `_integrity` block at the top level of
`process-log.json`:

```json
"_integrity": {
  "algorithm":   "SHA-256-CHAIN",
  "chain_length": 12,
  "head_hash":   "<_hash of the last event in the array>",
  "session_id":  "<UUID v4 — same as top-level session_id>",
  "note":        "Per-event chained hash. Verify using spec §5.2."
}
```

The `head_hash` is the `_hash` value of the final event in the `events` array
(typically `session_end`). A verifier can:
1. Recompute the hash chain from the first event
2. Compare the final computed hash against `_integrity.head_hash`
3. If they match: log is intact. If not: the log has been modified.

### 5.4 Reference Implementation

see [`spec/verification/verify.py`](./verification/verify.py) for a reference implementation of the verification logic.

### 5.5 Migration from v0.1 Bulk Hash

TWFF v0.1 used a single bulk hash of the entire `events` array:

```text
SHA-256( JSON.stringify(events, sort_keys=True) + session_id )
```

This is now superseded by the per-event chain (§5.2). Implementers producing
v0.1 logs without `_hash` fields on individual events SHOULD upgrade to the
per-event chain. Consumers MUST accept both formats and use whichever
`_integrity.algorithm` field is present (`"SHA-256"` for v0.1 bulk,
`"SHA-256-CHAIN"` for per-event chain).

### 5.6 Future: Digital Signatures (v1.5+)

The chained hash model is designed to compose with digital signatures.
A future version will support:

```xml
<!-- META-INF/signatures.xml -->
<Signature>
  <SignedInfo>
    <DigestMethod Algorithm="SHA-256-CHAIN"/>
    <DigestValue><!-- head_hash --></DigestValue>
  </SignedInfo>
  <SignatureValue><!-- RSA/ECDSA signature over head_hash --></SignatureValue>
  <KeyInfo><!-- Author's public key or key reference --></KeyInfo>
</Signature>
```

This will allow a TWFF consumer to:

1. Verify the hash chain (tamper detection — no key required)
2. Verify the digital signature (authorship proof — requires author's public key)

The relationship between `process-log.json` and `META-INF/signatures.xml` is:

- `process-log.json` carries the hash chain (`_hash` per event + `_integrity.head_hash`)
- `signatures.xml` signs the `head_hash` with a private key
- Verification: hash chain → head_hash → digital signature verification

---

## 6. Privacy Requirements

### 6.1 What MUST NOT be stored

- Individual keystroke content (only aggregated character counts and positions)
- Raw prompts or full AI responses (only metadata previews, MUST be truncated to ≤100 characters)
- Personally identifiable information beyond the `user_id`
- Screen recordings, mouse movements, or biometric data

### 6.2 `user_id` Requirements

- MUST be anonymous and contain no PII
- SHOULD be generated locally by the author (not assigned by a server)
- SHOULD be rotatable between sessions
- MUST NOT be tied to any account, email address, or device identifier

### 6.3 Data Sovereignty

Implementers MUST generate and store all TWFF data locally on the author's machine by default. No telemetry MUST be transmitted to any third-party server without explicit, informed author consent.

---

## 7. Visualisation

Implementations MAY provide visualisation of the composition process by:

1. Parsing the XHTML content into a DOM tree
2. For each event with `position_start` and `position_end`, locating the corresponding text range
3. Wrapping the range in a `<span>` with appropriate `class` and `data-tooltip` attributes
4. Rendering the annotated document with a legend

Reference CSS classes (used in Glass Box):

| Annotation | CSS Class | Colour |
|---|---|---|
| AI paraphrase | `ann-paraphrase` | Blue tint (`#3b82f6`) |
| AI generated | `ann-generated` | Green tint (`#10b981`) |
| External paste | `ann-external` | Amber tint (`#f59e0b`) |
| AI completion | `ann-completion` | Violet tint (`#8b5cf6`) |

---

## 8. Conformance

A **conformant producer** MUST:
- Generate a valid ZIP archive with the required directory structure
- Include `content/document.xhtml` as valid XHTML
- Include `meta/process-log.json` conforming to the schema in §4
- Record all AI interactions occurring during the session
- Not store prohibited data (§6.1)
- Generate a `user_id` that satisfies §6.2

A **conformant consumer** MUST:
- Accept any container produced by a conformant producer
- Validate `process-log.json` against the schema before processing
- Verify the `_integrity` hash if present and report any mismatch

---

## Appendix A — JSON Schema

Machine-readable JSON Schema for `process-log.json`: [`spec/process-log.schema.json`](./process-log.schema.json)

## Appendix B — References

1. Liang, W., et al. "GPT Detectors Are Biased Against Non-Native English Writers." *NeurIPS 2023*.
2. Weber-Wulff, D., et al. "Testing of Detection Tools for AI-Generated Text." *International Journal for Educational Integrity*, 2023.
3. European Parliament. *Regulation (EU) 2024/1689 (AI Act)*. Official Journal of the European Union, 2024.
4. EU AI Act, Article 50: Transparency obligations for providers of general-purpose AI systems.
5. EU AI Act, Article 52: Transparency obligations for providers and users of certain AI systems.
6. EU AI Act, Recital 72: Explainability and human oversight in high-risk contexts.
